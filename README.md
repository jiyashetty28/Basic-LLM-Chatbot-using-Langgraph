# ğŸ¤– Basic Chatbot using LangGraph & Groq API

Welcome to this minimal yet functional chatbot project that leverages the **LangGraph Graph API** and **Groq's LLaMA3-8B-8192 model**! This chatbot demonstrates how to structure conversational flows using a graph-based state machine and large language models.

---

## ğŸ“Œ Features

- ğŸŒ Built using **LangGraph** â€“ A graph-based framework for building LLM-powered applications.
- ğŸš€ Powered by **Groq API** with **LLaMA3-8B-8192** model.
- ğŸ” Graph execution flow: Define states â†’ Add LLM node â†’ Connect via edges â†’ Compile â†’ Invoke.
- ğŸ§  Stateful memory with message history via `add_messages`.
- ğŸ” Visualizes graph using Mermaid.

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ 1-basicchatbot.ipynb     # Jupyter Notebook with complete chatbot code
â”œâ”€â”€ .env                     # Stores your Groq API Key
â””â”€â”€ README.md                # Project documentation
```

---

## ğŸ§° Requirements

Make sure you have the following Python packages installed:

```bash
pip install langgraph langchain langchain-groq python-dotenv
```

---

## ğŸ” .env Configuration

Create a `.env` file in the same directory as your notebook/script and add:

```env
GROQ_API_KEY=your_groq_api_key_here
```

---

## ğŸ§± How It Works

### 1. **Define State**

```python
class State(TypedDict):
    messages: Annotated[list, add_messages]
```

The chatbot keeps track of all messages in a list using `add_messages`, which appends new user/LLM messages to the state.

---

### 2. **Initialize Groq LLM**

```python
from langchain_groq import ChatGroq
llm = ChatGroq(model="llama3-8b-8192")
```

You can also use `init_chat_model("groq:llama3-8b-8192")` for compatibility with LangChain.

---

### 3. **Define Node Function**

```python
def chatbot(state: State):
    return {"messages": [llm.invoke(state["messages"])]}
```

The chatbot node takes the current state and returns a new message generated by the LLM.

---

### 4. **Build and Compile Graph**

```python
graph_builder.add_node("llmchatbot", chatbot)
graph_builder.add_edge(START, "llmchatbot")
graph_builder.add_edge("llmchatbot", END)

graph = graph_builder.compile()
```

This builds the LangGraph with a simple START â†’ LLM â†’ END flow.

---

### 5. **Invoke the Chatbot**

```python
response = graph.invoke({"messages": "Hiiii"})
print(response["messages"][-1].content)
```

---

## ğŸ§  Graph Visualization

To visualize the LangGraph structure:

```python
from IPython.display import Image, display
display(Image(graph.get_graph().draw_mermaid_png()))
```

---

## ğŸ“¸ Demo Output

```text
Input:  Hiiii
Output: Hello! How can I help you today?
```

---

## ğŸ’¡ Notes

- This is a **minimal working prototype**. You can extend it with more nodes like context handling, retrieval, tools, or memory chains.
- You can swap out Groq with **OpenAI**, **Mistral**, or any other LLM backend supported by LangChain.
- Don't forget to **keep your API keys secure**.

---

## âœ¨ Credits

- ğŸ§  [LangGraph](https://github.com/langchain-ai/langgraph)
- âš¡ [Groq API](https://console.groq.com/)
- ğŸ¤– [LangChain](https://www.langchain.com/)

---

## ğŸ“œ License

This project is licensed under the MIT License. Feel free to modify and build upon it!




